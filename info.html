<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
  	<meta http-equiv="x-ua-compatible" content="ie=edge" >
  	<meta name="viewport" content="width=device-width, initial-scale=1.0" >

	<!-- Primary Meta Tags -->
    <title>Huffman Compression Technique</title>
    <link rel="shortcut icon" href="assets/favicon.ico">
    <meta name="title" content="Huffman Compression Technique">
    <meta name="description" content="An online .txt file compressor, de-compressor tool which uses Huffman Coding for Lossless data compression.">
    <meta name="keywords" content="Huffman Compression Technique, encoding,encoder,huffman, huffman-coding, lossless, huffman-compression-algorithm, txt, lossless-compression-algorithm, file-compression, huffman-encoder, huffman-decoder, huffman-encoding, txt-encode, txt-decode, lossless-compression, lossless-data-compression, filecompressor, online-file-compressor, txt-compressor, GZIP, Brotli, WebP, png, online file compression, file compressor, txt compression, txt compressor, txt encoding, online txt compressor, txt decompressor, samirpaul, SamirPaul1, SamirPaulb, Samir Paul, txt compressor github, gitpages, website, txt compressor website">
    <meta name="robots" content="index, follow">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="language" content="English">
    <meta name="author" content="Samir Paul">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://samirpaulb.github.io/txt-compressor/info.html">
    <meta property="og:title" content="Huffman Compression Technique">
    <meta property="og:description" content="An online .txt file compressor, de-compressor tool which uses Huffman Coding for Lossless data compression.">
    <meta property="og:image" content="https://raw.githubusercontent.com/SamirPaulb/assets/main/huffman-algorithm_python-txt-compressor-webimage-samirpaul.jpg">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://samirpaulb.github.io/txt-compressor/info.html">
    <meta property="twitter:title" content="Huffman Compression Technique">
    <meta property="twitter:description" content="An online .txt file compressor, de-compressor tool which uses Huffman Coding for Lossless data compression.">
    <meta property="twitter:image" content="https://raw.githubusercontent.com/SamirPaulb/assets/main/huffman-algorithm_python-txt-compressor-webimage-samirpaul.jpg">
    <link rel="canonical" href="https://samirpaul.in/txt-compressor/info.html"/>
	
    <link type="text/css" rel="stylesheet" href="styles.css">
    <style>
    body { background-color: #fffde0; }
    #pageUpButton {
        position: fixed;              
        bottom: 20px;                
        right: 20px;                 
        background-color: rgba(255, 255, 255, 0.7); 
        border: none;                
        border-radius: 5px;         
        padding: 10px;              
        box-shadow: 0 2px 5px rgba(0, 0, 0, 0.3); 
        text-decoration: none;       
        z-index: 1000;              
        transition: background-color 0.3s; 
    }

    #pageUpButton:hover {
        background-color: rgba(255, 255, 255, 1); 
    }
    #pageUpButton img {
        width: 50px;  /* Increase width */
        height: 50px; /* Increase height */
    }

    
  	</style>
	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-CP4QE6ZEV0"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-CP4QE6ZEV0');
	</script>
	
</head>

<body>
    <a href="index.html" class="links"> &lt- Go Back </a>
    <center><h1><p style="color:red"><a href="index.html" style="color:red">This website</a> uses Huffman Coding to compress data!</p> </h1></center>
    <ul>
        <li><b>Huffman Coding</b>  is a popular technique used for <b>Lossless Data Compression</b>.</li>
<h2 style="color:blue">Lossles Compression:</h2>
        <ol><b>Lossless compression</b> is a class of data compression algorithms that allows the original data to be perfectly reconstructed from the compressed data. Lossless compression methods are <b>reversible</b>. Examples of lossless compression include <b>GZIP</b>, <b>Brotli</b>, <b>WebP</b>, and <b>PNG</b>.</ol>
        <ol>Lossles Compression is preffered for text file compression, while Lossy Compression is generally preferred
            for audio, video and image files.</ol>
        <ol>File formats like <b>ZIP</b> use Lossless compression, while formats like <b>MP3</b> and <b>JPEG</b> use
            Lossy compression</ol>
        <ol><b>Data compression ratio</b> , also known as compression power, is a measurement of the relative reduction
            in size of data representation produced by a data compression algorithm. It is typically expressed as the
            division of uncompressed size by compressed size. Thus, a representation that compresses a file's storage
            size from 10 MB to 2 MB has a compression ratio of 10/2 = 5
        </ol>
        <center><img src="images/info-images/lossless-lossy-data-compression.png" alt="haffman-tree-and-binary-code-example.jpeg" loading="lazy" height="130" width="60%"></center>
        
        <br>
	<h2 style="color:blue">Greedy Algorithm:</h2>
	    <ol>Greedy is an algorithmic paradigm that builds up a solution piece by piece, always choosing the next piece that offers the most obvious and immediate benefit. Greedy algorithms are used for optimization problems. 
            <ol>Following are some standard algorithms that are Greedy algorithms:
<li>1) Kruskal’s Minimum Spanning Tree (MST): 
In Kruskal’s algorithm, we create an MST by picking edges one by one. The Greedy Choice is to pick the smallest weight edge that doesn’t cause a cycle in the MST constructed so far
</li>
<li>
2) Prim’s Minimum Spanning Tree: 
In Prim’s algorithm also, we create a MST by picking edges one by one. We maintain two sets: a set of the vertices already included in MST and the set of the vertices not yet included. The Greedy Choice is to pick the smallest weight edge that connects the two sets
</li>
<li>
3) Dijkstra’s Shortest Path: 
Dijkstra’s algorithm is very similar to Prim’s algorithm. The shortest-path tree is built up, edge by edge. We maintain two sets: a set of the vertices already included in the tree and a set of the vertices not yet included. The Greedy Choice is to pick the edge that connects the two sets and is on the smallest weight path from the source to the set that contains not yet included vertices
</li>
<li>
4) Huffman Coding: 
Huffman Coding is a loss-less compression technique. It assigns variable-length bit codes to different characters. The Greedy Choice is to assign the least bit length code to the most frequent character.
</li>
The greedy algorithms are sometimes also used to get an approximation for Hard optimization problems. For example, Traveling Salesman Problem is an NP-Hard problem. A Greedy choice for this problem is to pick the nearest unvisited city from the current city at every step. These solutions don’t always produce the best optimal solution but can be used to get an approximately optimal solution.

Here let us see one such problem that can be solved using Greedy algorithm</ol>

An optimization problem can be solved using Greedy if the problem has the following property: 


At every step, we can make a choice that looks best at the moment, and we get the optimal solution to the complete problem. </ol>
       <h2 style="color:blue">Huffman Code:</h2>
        <ol>
            A <b>Huffman code</b> is a particular type of optimal prefix code that is commonly used for lossless data
            compression. The process of finding or using such a code proceeds by means of Huffman coding, an algorithm
            developed by David A. Huffman.
        </ol>
        <ol>
            The output from Huffman's algorithm can be viewed as a <b>variable-length code table</b> 
            for encoding a source symbol (such as a character in a file). The algorithm derives this table from the
            estimated probability or frequency of occurrence (weight) for each possible value of the source symbol.
        </ol>
        <ol><b>Prefix Codes</b>, means the codes (bit sequences) are assigned in such a way that the code assigned to
            one character is not the prefix of code assigned to any other character. This is how Huffman Coding makes
            sure that there is <b>no ambiguity</b> when decoding the generated bitstream.
        </ol>
        
        <center><img src="images/info-images/huffman-coding.png" alt="haffman-tree-and-binary-code-example.jpeg" loading="lazy"  height="180" width="60%"></center>
        <br>
        <center><p>A Huffman coding tree built from this character frequency table: A=0.6, B=0.2, C=0.07, D=0.06, E=0.05, F=0.02.</p></center>
        <center><img src="images/info-images/data-compression-with-huffmans-algorithm.png"  loading="lazy" alt="data-compression-with-huffmans-algorithm.png" height="200" width="50%"></center>
        
        <br>
        
<h2 style="color:blue">Compression:</h2>
        <li>Huffman Encoding is an algorithm which uses frequency (or probability) feature of symbols and a binary tree structure. It consists of the following 3 steps:
            <ol>
                <li> Probability Calculation & Ordering the Symbols</li>
                <li>Binary Tree Transformation</li>
                <li>Assigning Codes to the Symbols</li>
            </ol>
        </li>
        <li>
            We count the number of each symbol in the whole data, then we calculate the “probability” of each symbol by dividing that count by the total number of characters in the data. Since its an algorithm using probability, more common symbols — the symbols having higher probability — are generally represented using fewer bits than less common symbols. This is one of the advantageous sides of Huffman Encoding. </li>
             <li>As an example, for the following data having 5 different symbols as A B C D E, we have the probabilities as shown right:</li>
        <br>
        <center><img src="images/info-images/compression1.png" alt="compression1" loading="lazy"  height="150" width="70%"></center>
        <li>Then we easily order the symbols according to their probabilities representing each symbol as a node and call that our “collection”. Now, we are ready to pass the next step.</li>
        <center><img src="images/info-images/compression2.png" alt="compression2" loading="lazy"  height="150" width="70%"></center>
        <li>Binary Tree Transformation:</li>
        <ol>1. From the collection, we pick out the two nodes with the smallest sum of probabilities and combine them into a new tree whose root has the probability equal to that sum.</ol>
        <ol>2. We add the new tree back into the collection.</ol>
        <ol>3. We repeat this process until one tree encompassing all the input probabilities has been constructed.<ol>
        <center><img src="images/info-images/compression3.png" alt="compression3" loading="lazy"  height="250" width="70%"></center>
        <center><img src="images/info-images/compression4.png" alt="compression4" loading="lazy"  height="250" width="70%"></center>
        <center><img src="images/info-images/compression5.png" alt="compression5" loading="lazy"  height="200" width="70%"></center>
       <br>
        <ol>As a conclusion, we see that the compression ratio does not change with the growing amount of data, and this ratio is close to 2:1. We can say that Huffman Encoding is an algorithm that compresses the data to its half size. Although it is old, it is still an effective compression algorithm! </ol>


<h2 style="color:blue">De-compression:</h2>
        <li>Having our Binary Huffman Tree obtained during encode phase, decoding is a very simple process to perform.</li>

		<li>Let’s consider we have the same example with Huffman Encoding post, therefore we have AAAAAAABCCCCCCDDEEEEE as our initial data and 000000000000001110101010101011101101010101010 as encoded output with the following Huffman Tree:</li>
        <br>
        <center><img src="images/info-images/huffman-tree-for-decoding.png" alt="huffman-tree-for-decoding.png"  loading="lazy" height="250" width="60%"></center>
        <br>
        <li>Now the only thing we should do is starting from the head of Huffman Tree and from the beginning of the encoded data, each time we encounter 1 we go right and while we encounter 0, we go left through the Huffman Tree. When we reach at a leaf node, we obtain the symbol! Then we just start again from the head of Huffman Tree while moving forward on encoded data.</li>
         <li>Data compression is a topic of many applications and it has various different types of algorithms beside of “frequency based” Huffman Algorithm. You can check for “dictionary based” methods like LZ77 LZ78 LZW which are useful for image compression especially.</li>
    <br>

    <a href="#" id="pageUpButton" title="Scroll to top">
        <img src="assets/up.png" alt="Up" style="width: 30px; height: 30px;">
    </a>
    
    <script>
        document.getElementById("pageUpButton").addEventListener("click", function(event) {
            event.preventDefault(); // Prevent default anchor behavior
            window.scrollTo({
                top: 0,
                behavior: 'smooth' // Smooth scroll
            });
        });

        document.querySelectorAll('.dropdown-header').forEach(header => {
            header.addEventListener('click', () => {
                const content = header.nextElementSibling; // Get the next sibling (the dropdown content)
                if (content.style.display === "block") {
                    content.style.display = "none"; // Hide if already visible
                } else {
                    content.style.display = "block"; // Show if hidden
                }
            });
        });
        
    </script>
</body>

</html>
